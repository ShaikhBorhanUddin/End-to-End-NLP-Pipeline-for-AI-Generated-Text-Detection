# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Yx-swJ5RPP_UmJPVT1kMi24ONk4pT463
"""

# This is the consolidated code for your app.py file. This includes all the functions,
# model loading, and the Gradio interface definition.
import gradio as gr
import lime
from lime.lime_text import LimeTextExplainer
import numpy as np
import torch
import matplotlib.pyplot as plt
import tempfile
import os
import string

# Import DistilBert classes for model loading
from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification

# --- Model and Tokenizer Loading (Adjusted for local deployment) ---
# In a deployed environment, models are usually saved locally relative to the app.py
MODEL_PATH = "./distilbert_model" # This will be the directory where you save your model

# Load tokenizer and model
tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_PATH)
model = DistilBertForSequenceClassification.from_pretrained(MODEL_PATH)

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval() # Set model to evaluation mode

class_names = ["Human", "AI"]

# --- Predictor Function ---
def predictor(texts):
    model.eval() # Ensure model is in evaluation mode
    inputs = tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors='pt')
    input_ids = inputs['input_ids'].to(device)
    attention_mask = inputs['attention_mask'].to(device)

    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)

    logits = outputs.logits
    probabilities = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()
    return probabilities

# --- LIME Explainer Initialization ---
explainer = LimeTextExplainer(
    class_names=class_names,
    split_expression=lambda text: text.split(' ')
)

# --- SHAP Explainer Initialization ---
def shap_predictor(texts):
    model.eval() # Set model to evaluation mode
    inputs = tokenizer(texts.tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt')
    input_ids = inputs['input_ids'].to(device)
    attention_mask = inputs['attention_mask'].to(device)

    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)

    logits = outputs.logits
    probabilities = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()
    return probabilities

masker = shap.maskers.Text(tokenizer, mask_token='<unk>')
shap_explainer = shap.Explainer(shap_predictor, masker, output_names=class_names)

# --- Bar Chart Visualization Function ---
def create_bar_chart_image(word_scores, title):
    if not word_scores:
        return None

    sorted_scores = sorted(word_scores, key=lambda item: abs(item[1]), reverse=True)
    top_n = 15
    if len(sorted_scores) > top_n:
        sorted_scores = sorted_scores[:top_n]

    sorted_scores = sorted_scores[::-1]

    words = [item[0] for item in sorted_scores]
    scores = [item[1] for item in sorted_scores]

    colors = ['red' if score > 0 else 'green' for score in scores]

    fig, ax = plt.subplots(figsize=(10, len(words) * 0.6 + 2))

    ax.barh(words, scores, color=colors)
    ax.set_xlabel('Contribution Score')
    ax.set_title(title)
    ax.tick_params(axis='y', length=0)
    ax.set_yticks(words)

    plt.tight_layout()

    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_file:
        filepath = tmp_file.name
        plt.savefig(filepath)

    plt.close(fig)

    return filepath

# --- LIME Explanation Function for Gradio ----
def generate_lime_html_explanation_for_gradio(user_text):
    if not user_text:
        return "Please enter some text for explanation.", []

    explanation_user = explainer.explain_instance(user_text, predictor, num_features=10, num_samples=50)

    exp_list = explanation_user.as_list()
    word_weights = {f.lower().strip(string.punctuation): weight for f, weight in exp_list}

    probabilities = predictor([user_text])[0]
    predicted_class_idx = np.argmax(probabilities)
    predicted_class_name = class_names[predicted_class_idx]

    html_parts = []
    original_words = user_text.split()

    lime_exp_list_for_chart = []

    for word in original_words:
        normalized_word = word.lower().strip(string.punctuation)
        weight = word_weights.get(normalized_word, 0)

        color = "#ffffff"
        alpha_intensity = min(1.0, abs(weight) * 3 + 0.2)

        if predicted_class_name == 'Human':
            if weight > 0:
                color = f"rgba(0, 128, 0, {alpha_intensity})"
                score_for_ai_chart = -abs(weight)
            else:
                color = f"rgba(255, 0, 0, {alpha_intensity})"
                score_for_ai_chart = abs(weight)
        else:
            if weight > 0:
                color = f"rgba(255, 0, 0, {alpha_intensity})"
                score_for_ai_chart = abs(weight)
            else:
                color = f"rgba(0, 128, 0, {alpha_intensity})"
                score_for_ai_chart = -abs(weight)

        html_parts.append(f'<span style="background-color: {color}; padding: 2px; border-radius: 3px;">{word}</span>')
        if weight != 0:
            lime_exp_list_for_chart.append((word, score_for_ai_chart))

    predicted_text = f"<p><b>Predicted Class:</b> {predicted_class_name} (Probability: {probabilities[predicted_class_idx]:.4f})</p>"

    legend = """
    <p><b>LIME Explanation Legend:</b></p>
    <ul>
        <li><span style="background-color: rgba(0, 128, 0, 0.5); padding: 2px; border-radius: 3px;">Green shades</span>: Words contributing positively to the 'Human' class.</li>
        <li><span style="background-color: rgba(255, 0, 0, 0.5); padding: 2px; border-radius: 3px;">Red shades</span>: Words contributing positively to the 'AI' class.</li>
        <li>Stronger colors indicate higher contribution.</li>
    </ul>
    """

    return f"{predicted_text}<div>{' '.join(html_parts)}</div>{legend}", lime_exp_list_for_chart

# --- SHAP Explanation Function for Gradio ---
def generate_shap_html_explanation_for_gradio(user_text):
    if not user_text:
        return "Please enter some text for explanation.", []

    shap_values_obj = shap_explainer(np.array([user_text]))[0]

    words = shap_values_obj.data
    values = shap_values_obj.values

    probabilities = predictor([user_text])[0]
    predicted_class_idx = np.argmax(probabilities)
    class_name_for_explanation = class_names[predicted_class_idx]
    overall_prediction_score = probabilities[predicted_class_idx]

    ai_class_idx = class_names.index('AI')
    if len(values.shape) > 1:
        shap_values_for_coloring = values[:, ai_class_idx]
    else:
        shap_values_for_coloring = values

    html_parts = []
    max_val = np.max(np.abs(shap_values_for_coloring))
    if max_val == 0: max_val = 1

    shap_values_for_chart = []
    for word, shap_val in zip(words, shap_values_for_coloring):
        shap_values_for_chart.append((word, shap_val))

        color = "#ffffff"
        if shap_val > 0:
            alpha = min(0.8, shap_val / max_val * 0.8 + 0.2)
            color = f"rgba(255, 0, 0, {alpha})"
        elif shap_val < 0:
            alpha = min(0.8, abs(shap_val) / max_val * 0.8 + 0.2)
            color = f"rgba(0, 128, 0, {alpha})"

        html_parts.append(f'<span style="background-color: {color}; padding: 1px; border-radius: 2px;">{word}</span>')

    explanation_html = f"<p><b>Predicted Class:</b> {class_name_for_explanation} (Score: {overall_prediction_score:.4f})</p>"
    explanation_html += f"<div>{' '.join(html_parts)}</div>"

    legend = """
    <p><b>SHAP Explanation Legend:</b></p>
    <ul>
        <li><span style="background-color: rgba(255, 0, 0, 0.5); padding: 2px; border-radius: 3px;">Red shades</span>: Words contributing positively to the 'AI' class.</li>
        <li><span style="background-color: rgba(0, 128, 0, 0.5); padding: 2px; border-radius: 3px;">Green shades</span>: Words contributing positively to the 'Human' class.</li>
        <li>Stronger colors indicate higher absolute contribution.</li>
    </ul>
    """
    return f"{explanation_html}{legend}", shap_values_for_chart

# --- Combined function for Gradio Interface ---
def explain_text_with_both(user_text):
    lime_output_html, lime_exp_list = generate_lime_html_explanation_for_gradio(user_text)
    shap_output_html, shap_values_for_chart = generate_shap_html_explanation_for_gradio(user_text)

    lime_chart_path = create_bar_chart_image(lime_exp_list, 'LIME Explanation of Influencing Words')
    shap_chart_path = create_bar_chart_image(shap_values_for_chart, 'SHAP Explanation of Influencing Words')

    return lime_output_html, lime_chart_path, shap_output_html, shap_chart_path


# Define the Gradio Blocks interface
with gr.Blocks() as demo:
    gr.Markdown("# LIME & SHAP Explanations for DistilBERT Text Classification")
    gr.Markdown("Enter a text to see LIME and SHAP explanations for how the model classifies it as Human or AI-generated.")

    with gr.Row():
        text_input = gr.Textbox(lines=5, label="Enter text to explain")

    with gr.Row():
        with gr.Column():
            gr.Markdown("## LIME Explanation")
            lime_html_output = gr.HTML(label="LIME Text Explanation")
            lime_image_output = gr.Image(label="LIME Feature Importance")

        with gr.Column():
            gr.Markdown("## SHAP Explanation")
            shap_html_output = gr.HTML(label="SHAP Text Explanation")
            shap_image_output = gr.Image(label="SHAP Feature Importance")

    text_input.change(
        fn=explain_text_with_both,
        inputs=text_input,
        outputs=[
            lime_html_output,
            lime_image_output,
            shap_html_output,
            shap_image_output
        ]
    )

demo.launch(debug=True) # debug=True is useful for development, removed in final deployment adding 'share = True'
